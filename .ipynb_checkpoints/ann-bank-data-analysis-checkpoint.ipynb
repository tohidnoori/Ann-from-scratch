{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc94a1f5-1f07-4300-bfa9-97625671b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # matplotlib is for drawing graphs\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.utils import resample # downsample the dataset\n",
    "from sklearn.model_selection import train_test_split # split data into training and testing sets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC # this will make a support vector machine for classificaiton\n",
    "from sklearn.model_selection import GridSearchCV #this will do cross validation\n",
    "from sklearn.metrics import confusion_matrix # this creates a confusion matrix\n",
    "from sklearn.decomposition import PCA # to perform PCA to plot the data\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd238aca-5349-409e-ba7f-7d07d44a0d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-proccessing\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"default of credit card clients.txt\",sep='\\t',header=1)\n",
    "df.drop('ID',axis=1,inplace=True)\n",
    "df.rename(columns={'default payment next month': 'DEFAULT'}, inplace=True)\n",
    "df_no_missing = df.loc[(df['MARRIAGE']!=0) & (df['EDUCATION']!=0)]\n",
    "df_no_missing.head()\n",
    "df_no_default = df_no_missing[df_no_missing['DEFAULT']==0]\n",
    "df_default = df_no_missing[df_no_missing['DEFAULT']==1]\n",
    "df_no_default_downsampled = resample(df_no_default,replace=False,n_samples=1000,random_state=42)\n",
    "df_default_downsampled = resample(df_default,replace=False,n_samples=1000,random_state=42)\n",
    "df_downsampled = pd.concat([df_no_default_downsampled,df_default_downsampled])\n",
    "X = df_downsampled.drop(['DEFAULT'],axis=1).copy()\n",
    "y = df_downsampled['DEFAULT'].copy()\n",
    "X_encoded = pd.get_dummies(X,columns=['SEX','EDUCATION','MARRIAGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6']).astype(int)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_encoded,y,random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "print(\"pre-proccessing\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73b690e-ed53-41ba-a4a9-66bdcc5acaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 81\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plotEquations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m equation2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{Ssr}\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{pred}\u001b[39;00m\u001b[38;5;124m} = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial (pred - real)^\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{pred}\u001b[39;00m\u001b[38;5;124m} = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msum2(pred - real)$\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m equation3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{pred}\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{b}\u001b[39;00m\u001b[38;5;124m} = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial sigmoid(out)}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{b}\u001b[39;00m\u001b[38;5;124m} = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;132;01m{d}\u001b[39;00m\u001b[38;5;132;01m{db}\u001b[39;00m\u001b[38;5;124msigmoid(out)*1$\u001b[39m\u001b[38;5;124m'\u001b[39m    \n\u001b[1;32m---> 11\u001b[0m \u001b[43mplotEquations\u001b[49m(equation1,equation2,equation3)\n\u001b[0;32m     12\u001b[0m equation1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{Ssr}\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial hiddenOutWeights} = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{Ssr}\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{pred}\u001b[39;00m\u001b[38;5;124m} \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcdot \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{pred}\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpartial hiddenOutWeights}$\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m     13\u001b[0m equation2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plotEquations' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Number of columns: {X_train_scaled.shape[1]}\")\n",
    "input_nodes_num = X_train_scaled.shape[1]\n",
    "hidden_nodes_num = 10\n",
    "output_nodes_num = 1\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "equation1 = r'$\\frac{\\partial \\text{Ssr}}{\\partial b} = \\frac{\\partial \\text{Ssr}}{\\partial \\text{pred}} \\cdot \\frac{\\partial \\text{pred}}{\\partial b}$'\n",
    "equation2 = r'$\\frac{\\partial \\text{Ssr}}{\\partial \\text{pred}} = \\sum\\frac{\\partial (pred - real)^{2}}{\\partial \\text{pred}} = \\sum2(pred - real)$'\n",
    "equation3 = r'$\\frac{\\partial \\text{pred}}{\\partial \\text{b}} = \\frac{\\partial sigmoid(out)}{\\partial \\text{b}} = \\frac{d}{db}sigmoid(out)*1$'    \n",
    "plotEquations(equation1,equation2,equation3)\n",
    "equation1 = r'$\\frac{\\partial \\text{Ssr}}{\\partial hiddenOutWeights} = \\frac{\\partial \\text{Ssr}}{\\partial \\text{pred}} \\cdot \\frac{\\partial \\text{pred}}{\\partial hiddenOutWeights}$' \n",
    "equation2 = ''\n",
    "equation3 = r'$\\frac{\\partial \\text{pred}}{\\partial \\text{hiddenOutWeights}} =  \\frac{d}{dhiddenOutWeights} \\cdot sigmoid(out)\\cdot hiddenNodes$'    \n",
    "plotEquations(equation1,equation2,equation3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca195943-da61-4163-b0a7-2d02f1669877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 14.561169614745467\n",
      "hidden_out_baises : -0.13028578780462347\n",
      "Initial Loss: 14.698139218725446\n",
      "hidden_out_baises : -0.4174031863576568\n",
      "Initial Loss: 15.632150540792772\n",
      "hidden_out_baises : -0.5377406072811436\n",
      "Initial Loss: 12.709433093110299\n",
      "hidden_out_baises : -0.545706394214704\n",
      "Initial Loss: 11.304469561411544\n",
      "hidden_out_baises : -0.4837266758689271\n",
      "Initial Loss: 11.675728456078403\n",
      "hidden_out_baises : -0.4259023770169194\n",
      "Initial Loss: 12.407449705733539\n",
      "hidden_out_baises : -0.3473979512487429\n",
      "Initial Loss: 13.282114327911225\n",
      "hidden_out_baises : -0.26771259641995643\n",
      "Initial Loss: 13.856485072570111\n",
      "hidden_out_baises : -0.20497240064813604\n",
      "Initial Loss: 14.225291400401103\n",
      "hidden_out_baises : -0.16228225315637199\n",
      "Initial Loss: 14.38239675828593\n",
      "hidden_out_baises : -0.1403713031744122\n",
      "Initial Loss: 14.728816921272664\n",
      "hidden_out_baises : -0.12621037917689568\n",
      "Initial Loss: 14.714295144858088\n",
      "hidden_out_baises : -0.11794660013223303\n",
      "Initial Loss: 14.805240334543162\n",
      "hidden_out_baises : -0.11181021653441592\n",
      "Initial Loss: 14.901784561891759\n",
      "hidden_out_baises : -0.10686740533824465\n",
      "Initial Loss: 14.96435333186638\n",
      "hidden_out_baises : -0.10255500150086724\n",
      "Initial Loss: 14.96570259754142\n",
      "hidden_out_baises : -0.1013391411324595\n",
      "Initial Loss: 14.984801708084715\n",
      "hidden_out_baises : -0.10106128031436326\n",
      "Initial Loss: 14.98462003450981\n",
      "hidden_out_baises : -0.10115969436812472\n",
      "Initial Loss: 14.98446512623526\n",
      "hidden_out_baises : -0.10129946781435965\n",
      "Initial Loss: 14.984315246455731\n",
      "hidden_out_baises : -0.10144217387461785\n",
      "Initial Loss: 14.98416786844794\n",
      "hidden_out_baises : -0.1015834433277304\n",
      "Initial Loss: 14.98402265083102\n",
      "hidden_out_baises : -0.10172281947866096\n",
      "Initial Loss: 14.983879503347305\n",
      "hidden_out_baises : -0.10186029391336866\n",
      "Initial Loss: 14.983738366462557\n",
      "hidden_out_baises : -0.10199590816138218\n",
      "Initial Loss: 14.983599186124465\n",
      "hidden_out_baises : -0.10212970792858703\n",
      "Initial Loss: 14.983462894667541\n",
      "hidden_out_baises : -0.1022617379022938\n",
      "Initial Loss: 14.983332875606306\n",
      "hidden_out_baises : -0.10239204122476117\n",
      "Initial Loss: 14.98320457571334\n",
      "hidden_out_baises : -0.10252065950050976\n",
      "Initial Loss: 14.983079264745893\n",
      "hidden_out_baises : -0.10264763286118452\n",
      "Initial Loss: 14.98295892068031\n",
      "hidden_out_baises : -0.1027730000333139\n",
      "Initial Loss: 14.982840102412482\n",
      "hidden_out_baises : -0.10289679840292662\n",
      "Initial Loss: 14.982722773195935\n",
      "hidden_out_baises : -0.10301906407656793\n",
      "Initial Loss: 14.982606897600178\n",
      "hidden_out_baises : -0.10313983193887862\n",
      "Initial Loss: 14.98249244144783\n",
      "hidden_out_baises : -0.10325913570696987\n",
      "Initial Loss: 14.982379371755552\n",
      "hidden_out_baises : -0.10337700798179686\n",
      "Initial Loss: 14.982267656678431\n",
      "hidden_out_baises : -0.1034934802967403\n",
      "Initial Loss: 14.982158546706305\n",
      "hidden_out_baises : -0.1036085831635683\n",
      "Initial Loss: 14.982052968874948\n",
      "hidden_out_baises : -0.10372234611595037\n",
      "Initial Loss: 14.981948623017617\n",
      "hidden_out_baises : -0.10383479775068229\n",
      "Initial Loss: 14.981845481920109\n",
      "hidden_out_baises : -0.10394596576676367\n",
      "Initial Loss: 14.98174351925856\n",
      "hidden_out_baises : -0.10405587700245948\n",
      "Initial Loss: 14.981642709560704\n",
      "hidden_out_baises : -0.10416455747047557\n",
      "Initial Loss: 14.981543028169257\n",
      "hidden_out_baises : -0.10427203239135552\n",
      "Initial Loss: 14.98144445120725\n",
      "hidden_out_baises : -0.10437832622521094\n",
      "Initial Loss: 14.981347837954367\n",
      "hidden_out_baises : -0.10448346270188501\n",
      "Initial Loss: 14.981254987424428\n",
      "hidden_out_baises : -0.10458746484963616\n",
      "Initial Loss: 14.981163140054829\n",
      "hidden_out_baises : -0.1046903550224332\n",
      "Initial Loss: 14.981072275351005\n",
      "hidden_out_baises : -0.1047921549259404\n",
      "Initial Loss: 14.98098237343675\n",
      "hidden_out_baises : -0.10489288564226801\n",
      "Initial Loss: 14.980895174656492\n",
      "hidden_out_baises : -0.10499256765355204\n",
      "Initial Loss: 14.980811327691228\n",
      "hidden_out_baises : -0.10509122086444414\n",
      "Initial Loss: 14.980730411139133\n",
      "hidden_out_baises : -0.10518886462355041\n",
      "Initial Loss: 14.98065273563084\n",
      "hidden_out_baises : -0.10528551774389704\n",
      "Initial Loss: 14.980575846384383\n",
      "hidden_out_baises : -0.1053811985224616\n",
      "Initial Loss: 14.980499728367157\n",
      "hidden_out_baises : -0.10547592475882764\n",
      "Initial Loss: 14.980424366970546\n",
      "hidden_out_baises : -0.10556971377300944\n",
      "Initial Loss: 14.980349747994076\n",
      "hidden_out_baises : -0.1056625824224868\n",
      "Initial Loss: 14.980275857630268\n",
      "hidden_out_baises : -0.10575454711848992\n",
      "Initial Loss: 14.980202682450253\n",
      "hidden_out_baises : -0.10584562384158383\n",
      "Initial Loss: 14.98013020939\n",
      "hidden_out_baises : -0.10593582815657786\n",
      "Initial Loss: 14.980058425737152\n",
      "hidden_out_baises : -0.10602517522679576\n",
      "Initial Loss: 14.979989361367748\n",
      "hidden_out_baises : -0.10611367982774701\n",
      "Initial Loss: 14.979924830012369\n",
      "hidden_out_baises : -0.10620135636021692\n",
      "Initial Loss: 14.979860896270377\n",
      "hidden_out_baises : -0.10628821886281739\n",
      "Initial Loss: 14.979797549697706\n",
      "hidden_out_baises : -0.10637428102401567\n",
      "Initial Loss: 14.979734780118976\n",
      "hidden_out_baises : -0.10645955619366736\n",
      "Initial Loss: 14.979672577618345\n",
      "hidden_out_baises : -0.10654405739408739\n",
      "Initial Loss: 14.979610932530758\n",
      "hidden_out_baises : -0.10662779733066582\n",
      "Initial Loss: 14.979549835433534\n",
      "hidden_out_baises : -0.10671078840206469\n",
      "Initial Loss: 14.979489277138336\n",
      "hidden_out_baises : -0.10679304271000588\n",
      "Initial Loss: 14.961814204300518\n",
      "hidden_out_baises : -0.10687457206867544\n",
      "Initial Loss: 14.961151390094935\n",
      "hidden_out_baises : -0.10695538801375686\n",
      "Initial Loss: 14.960782322274989\n",
      "hidden_out_baises : -0.10703550181111758\n",
      "Initial Loss: 14.960513999221138\n",
      "hidden_out_baises : -0.10711492446515539\n",
      "Initial Loss: 14.960297410229046\n",
      "hidden_out_baises : -0.10719366672682983\n",
      "Initial Loss: 14.9601125052301\n",
      "hidden_out_baises : -0.10727173910138708\n",
      "Initial Loss: 14.959949089944727\n",
      "hidden_out_baises : -0.10734915185579247\n",
      "Initial Loss: 14.959801265239783\n",
      "hidden_out_baises : -0.10742591502588608\n",
      "Initial Loss: 14.959665307543483\n",
      "hidden_out_baises : -0.10750203842327029\n",
      "Initial Loss: 14.959538714309423\n",
      "hidden_out_baises : -0.10757753164194783\n",
      "Initial Loss: 14.95941972164437\n",
      "hidden_out_baises : -0.10765240406471052\n",
      "Initial Loss: 14.959307038895062\n",
      "hidden_out_baises : -0.1077266648692996\n",
      "Initial Loss: 14.95919969269886\n",
      "hidden_out_baises : -0.1078003230343425\n",
      "Initial Loss: 14.959096930426844\n",
      "hidden_out_baises : -0.10787338734507694\n",
      "Initial Loss: 14.958998157786448\n",
      "hidden_out_baises : -0.1079458663988697\n",
      "Initial Loss: 14.958902897034752\n",
      "hidden_out_baises : -0.10801776861054307\n",
      "Initial Loss: 14.95881075813634\n",
      "hidden_out_baises : -0.10808910221750806\n",
      "Initial Loss: 14.9587214183329\n",
      "hidden_out_baises : -0.10815987528472783\n",
      "Initial Loss: 14.958634607341963\n",
      "hidden_out_baises : -0.10823009570950014\n",
      "Initial Loss: 14.958550096420101\n",
      "hidden_out_baises : -0.10829977122608078\n",
      "Initial Loss: 14.958467690139559\n",
      "hidden_out_baises : -0.1083689094101441\n",
      "Initial Loss: 14.958387220108227\n",
      "hidden_out_baises : -0.1084375176830984\n",
      "Initial Loss: 14.958308540106591\n",
      "hidden_out_baises : -0.10850560331624921\n",
      "Initial Loss: 14.958231522274296\n",
      "hidden_out_baises : -0.10857317343482635\n",
      "Initial Loss: 14.958156054085606\n",
      "hidden_out_baises : -0.10864023502187643\n",
      "Initial Loss: 14.95808203592557\n",
      "hidden_out_baises : -0.10870679492202613\n",
      "Initial Loss: 14.958009379129045\n",
      "hidden_out_baises : -0.10877285984512254\n",
      "Initial Loss: 14.957938004380408\n",
      "hidden_out_baises : -0.10883843636975177\n",
      "Initial Loss: 14.957867840396982\n",
      "hidden_out_baises : -0.10890353094664663\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "#hidden-input layer wieghts and biases\n",
    "input_hidden_weights = np.random.rand(input_nodes_num,hidden_nodes_num)\n",
    "input_hidden_baises = np.zeros(hidden_nodes_num)\n",
    "\n",
    "#hidden-output layer wieghts and biases\n",
    "hidden_out_weights = np.random.rand(hidden_nodes_num,output_nodes_num)\n",
    "hidden_out_baises = 0\n",
    "# print(f\"hidden_out_baises : {hidden_out_baises}\" )\n",
    "# print(f\"hidden_out_weights : {hidden_out_weights}\" )\n",
    "# print(f\"input_hidden_weights : {input_hidden_weights}\" )\n",
    "# print(f\"input_hidden_baises : {input_hidden_baises}\" )X_train_scaled[i]\n",
    "for epoch in range(100):\n",
    "    i =0\n",
    "    predicated_values = []\n",
    "    hidden_layer =[]\n",
    "    outputs_values =[]\n",
    "    for i in range(0,len(X_train_scaled)):\n",
    "        input_nodes = X_train_scaled[i]\n",
    "        pred,hidden_nodes,output_node = forward(input_nodes,input_hidden_weights,hidden_out_weights,input_hidden_baises,hidden_out_baises)\n",
    "        real = y_train.iloc[i]\n",
    "        outputs_values.append(output_node)\n",
    "        predicated_values.append(pred)\n",
    "        hidden_layer.append(hidden_nodes)\n",
    "    # mydf = pd.DataFrame({\n",
    "    #     'outputs': outputs_values,\n",
    "    #     'real': y_train,\n",
    "    #     'predicated': predicated_values\n",
    "    # })\n",
    "    # #print(mydf)\n",
    "\n",
    "    \n",
    "    outputs_values = np.array(outputs_values).flatten()\n",
    "    predicated_values = np.array(predicated_values).flatten()\n",
    "    hidden_layer = np.array(hidden_layer)\n",
    "    observed_values =  y_train.to_numpy()\n",
    "\n",
    "    ssr = np.sum((observed_values-predicated_values)**2)\n",
    "    loss = binary_cross_entropy(y_train.to_numpy(), outputs_values)\n",
    "    print(\"Initial Loss:\", loss)\n",
    "    \n",
    "     # Compute gradients for output layer\n",
    "    dSSR_dpred = predicated_values - observed_values  # Gradient of loss with respect to predictions\n",
    "    sigmoid_derivs = sigmoid_derivative(outputs_values)  # Derivative of sigmoid output\n",
    "    \n",
    "    d_output_weights = np.dot(hidden_layer.T, (dSSR_dpred * sigmoid_derivs).reshape(-1, 1))\n",
    "    d_output_biases = np.sum(dSSR_dpred * sigmoid_derivs, axis=0)\n",
    "    \n",
    "    # Compute gradients for hidden layer\n",
    "    d_hidden_error = (dSSR_dpred * sigmoid_derivs).reshape(-1, 1) @ hidden_out_weights.T * hidden_layer>0\n",
    "    \n",
    "    d_hidden_weights = np.dot(X_train_scaled.T, d_hidden_error)\n",
    "    d_hidden_biases = np.sum(d_hidden_error, axis=0)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    input_hidden_weights -= learning_rate * d_hidden_weights\n",
    "    input_hidden_baises -= learning_rate * d_hidden_biases\n",
    "    \n",
    "    hidden_out_weights -= learning_rate * d_output_weights\n",
    "    hidden_out_baises -= learning_rate * d_output_biases\n",
    "    print(f\"hidden_out_baises : {hidden_out_baises}\" )\n",
    "    # print(f\"hidden_out_weights : {hidden_out_weights}\" )\n",
    "    # print(f\"input_hidden_weights : {input_hidden_weights}\" )\n",
    "    #print(f\"input_hidden_baises : {input_hidden_baises}\" )\n",
    "    #print(f\"ssr : {ssr}\")\n",
    "    #print(d_output_weights)\n",
    "    #print(hidden_out_baises)\n",
    "    #print(hidden_out_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "334d81fa-f786-48e1-ae60-05b274f9bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(input_nodes1,input_hidden_weights1,hidden_out_weights1,input_hidden_baises1,hidden_out_baises1):\n",
    "    #initialize hidden nodes\n",
    "    hidden_nodes1 = np.dot(input_nodes1,input_hidden_weights1)\n",
    "    hidden_nodes1 = np.add(hidden_nodes1,input_hidden_baises1)\n",
    "    hidden_nodes1 = relu(hidden_nodes1)\n",
    "    #initialize out node\n",
    "    output_node1 = np.dot(hidden_nodes1,hidden_out_weights1)\n",
    "    output_node1 = np.add(output_node1,hidden_out_baises1)\n",
    "    predictions1 = sigmoid(output_node1)\n",
    "    return predictions1,hidden_nodes1,output_node1\n",
    "def plotEquations(q1,q2,q3):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax.text(0.5, 0.7, q1, fontsize=20, ha='center', va='center')\n",
    "    \n",
    "    ax.text(0.5, 0.5, q2, fontsize=20, ha='center', va='center')\n",
    "    \n",
    "    ax.text(0.5, 0.3, q3, fontsize=20, ha='center', va='center')\n",
    "    \n",
    "    plt.savefig('equations.png', bbox_inches='tight', pad_inches=0.1, dpi=300)\n",
    "    plt.show()\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def relu(x):\n",
    "    return np.maximum(0, x) \n",
    "def sigmoid_derivative(x):\n",
    "    sigmoid_x = sigmoid(x)\n",
    "    return sigmoid_x * (1 - sigmoid_x)\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "467410f5-1f14-4dae-aa71-7f2b320fad1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7800\n",
      "Accuracy: 0.5700\n",
      "Sensitivity (Recall): 0.1605\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range(0,len(X_test_scaled)):\n",
    "    input_nodes = X_test_scaled[i]\n",
    "    pred,_,_ = forward(input_nodes,input_hidden_weights,hidden_out_weights,input_hidden_baises,hidden_out_baises)\n",
    "    predictions.append(pred)\n",
    "binary_predictions = (np.array(predictions)>= 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, binary_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "    # Calculate precision, accuracy, and sensitivity\n",
    "precision = precision_score(y_test, binary_predictions)\n",
    "accuracy = accuracy_score(y_test, binary_predictions)\n",
    "sensitivity = recall_score(y_test, binary_predictions)\n",
    "\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Sensitivity (Recall): {sensitivity:.4f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d740f65-d9ed-4fd2-acee-5c55f3f601f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7c2a8be-e0cb-40da-b45b-2358377b6dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5909 - loss: 0.6754 - val_accuracy: 0.6833 - val_loss: 0.5903\n",
      "Epoch 2/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7159 - loss: 0.5635 - val_accuracy: 0.6533 - val_loss: 0.6307\n",
      "Epoch 3/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7377 - loss: 0.5331 - val_accuracy: 0.6700 - val_loss: 0.6004\n",
      "Epoch 4/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6935 - loss: 0.5673 - val_accuracy: 0.6833 - val_loss: 0.6353\n",
      "Epoch 5/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7347 - loss: 0.5370 - val_accuracy: 0.6700 - val_loss: 0.6302\n",
      "Epoch 6/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7390 - loss: 0.5264 - val_accuracy: 0.6567 - val_loss: 0.6139\n",
      "Epoch 7/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7509 - loss: 0.4779 - val_accuracy: 0.6967 - val_loss: 0.6074\n",
      "Epoch 8/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7403 - loss: 0.5022 - val_accuracy: 0.6767 - val_loss: 0.6348\n",
      "Epoch 9/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7314 - loss: 0.4972 - val_accuracy: 0.6900 - val_loss: 0.6308\n",
      "Epoch 10/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7752 - loss: 0.4584 - val_accuracy: 0.6533 - val_loss: 0.6581\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6686 - loss: 0.6949 \n",
      "Test Loss: 0.6928279995918274\n",
      "Test Accuracy: 0.6460000276565552\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input layer (automatically inferred)\n",
    "input_shape = X_train_scaled.shape[1]\n",
    "model.add(Input(shape=(input_shape,)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c1e8f-099f-427e-8915-79497213f0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "6991831720b726829475ab2fdaae779fa846493d282639f93ea99b469bb29648"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
